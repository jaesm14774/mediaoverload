"""Text2Image2Image ä½¿ç”¨ç¯„ä¾‹

å±•ç¤ºå¦‚ä½•ä½¿ç”¨ Text2Image2ImageStrategy é€²è¡Œå…©éšæ®µç”Ÿæˆï¼š
1. ç¬¬ä¸€éšæ®µï¼šText to Image ç”Ÿæˆå¤šå¼µåœ–ç‰‡
2. ç¯©é¸éšæ®µï¼šè‡ªå‹•ç¯©é¸ç¬¦åˆæè¿°çš„åœ–ç‰‡
3. ç¬¬äºŒéšæ®µï¼šå°ç¯©é¸å¾Œçš„åœ–ç‰‡é€²è¡Œ Image to Image äºŒæ¬¡ç”Ÿæˆ

ä½¿ç”¨å‰è«‹ç¢ºä¿ï¼š
1. ComfyUI å·²å•Ÿå‹•ä¸¦é‹è¡Œåœ¨ 8188 ç«¯å£
2. ç’°å¢ƒè®Šæ•¸å·²é…ç½®ï¼ˆmedia_overload.envï¼‰
3. æœ‰å¯ç”¨çš„è¦–è¦ºæ¨¡å‹ï¼ˆOpenRouter/Geminiï¼‰ç”¨æ–¼åœ–æ–‡åŒ¹é…åˆ†æ
"""

import sys
from pathlib import Path

# ç¢ºä¿å¯ä»¥å°å…¥å°ˆæ¡ˆæ¨¡çµ„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from lib.media_auto.strategies.base_strategy import GenerationConfig
from lib.media_auto.factory.strategy_factory import StrategyFactory
from lib.media_auto.models.vision.vision_manager import VisionManagerBuilder
import os


def example_text2image2image_basic():
    """ç¯„ä¾‹ 1: åŸºæœ¬çš„ Text2Image2Image ç”Ÿæˆ"""
    print("\n" + "="*60)
    print("ç¯„ä¾‹ 1: åŸºæœ¬çš„ Text2Image2Image ç”Ÿæˆ")
    print("="*60)
    
    # å‰µå»ºè¦–è¦ºç®¡ç†å™¨ï¼ˆç”¨æ–¼åœ–æ–‡åŒ¹é…åˆ†æï¼‰
    vision_manager = VisionManagerBuilder() \
        .with_vision_model('openrouter') \
        .with_text_model('openrouter') \
        .with_random_models(True) \
        .build()
    
    # é…ç½®åƒæ•¸
    config = GenerationConfig(
        generation_type='text2image2image',
        character='kirby',
        prompt='Kirby eating ramen with chopsticks',
        workflow_path='configs/workflow/nova-anime-xl.json',  # ç¬¬ä¸€éšæ®µå·¥ä½œæµ
        output_dir='output_media/t2i2i_output',
        image_system_prompt='stable_diffusion_prompt',
        similarity_threshold=0.9,  # ç¬¬ä¸€éšæ®µç¯©é¸é–¾å€¼
        additional_params={
            'strategies': {
                'text2image2image': {
                    'first_stage': {
                        'images_per_description': 4  # ç¬¬ä¸€éšæ®µç”Ÿæˆ 4 å¼µåœ–ç‰‡
                    },
                    'second_stage': {
                        'images_per_input': 1,  # ç¬¬äºŒéšæ®µæ¯å€‹è¼¸å…¥ç”Ÿæˆ 1 å¼µ
                        'denoise': 0.6,  # denoise æ¬Šé‡
                        'i2i_workflow_path': 'configs/workflow/example/image_to_image.json'  # ç¬¬äºŒéšæ®µå·¥ä½œæµ
                    }
                }
            }
        }
    )
    
    # å‰µå»ºç­–ç•¥ä¸¦åŸ·è¡Œ
    strategy = StrategyFactory.get_strategy(
        'text2image2image',
        vision_manager=vision_manager
    )
    strategy.load_config(config)
    
    print(f"\nğŸ“ æç¤ºè©: {config.prompt}")
    print(f"ğŸ“ ç¬¬ä¸€éšæ®µç”Ÿæˆæ•¸é‡: {config.additional_params['strategies']['text2image2image']['first_stage']['images_per_description']}")
    print(f"ğŸ“ ç›¸ä¼¼åº¦é–¾å€¼: {config.similarity_threshold}")
    print(f"ğŸ“ ç¬¬äºŒéšæ®µ denoise: {config.additional_params['strategies']['text2image2image']['second_stage']['denoise']}")
    print(f"ğŸ“‚ è¼¸å‡ºç›®éŒ„: {config.output_dir}")
    
    # ç”Ÿæˆæè¿°
    print("\nğŸ”„ æ­¥é©Ÿ 1: ç”Ÿæˆåœ–ç‰‡æè¿°...")
    strategy.generate_description()
    print(f"ğŸ“ ç”Ÿæˆçš„æè¿°: {strategy.descriptions[0] if strategy.descriptions else 'N/A'}")
    
    # ç”Ÿæˆåœ–ç‰‡ï¼ˆåŒ…å«å…©éšæ®µï¼‰
    print("\nğŸ”„ æ­¥é©Ÿ 2: é–‹å§‹å…©éšæ®µç”Ÿæˆ...")
    strategy.generate_media()
    
    # åˆ†æç¬¬äºŒéšæ®µçµæœ
    print("\nğŸ”„ æ­¥é©Ÿ 3: åˆ†æç¬¬äºŒéšæ®µçµæœ...")
    strategy.analyze_media_text_match(similarity_threshold=0.8)
    
    print(f"\nâœ… ç”Ÿæˆå®Œæˆï¼")
    print(f"ğŸ“Š ç¬¬ä¸€éšæ®µç”Ÿæˆ: {len(strategy.first_stage_images)} å¼µåœ–ç‰‡é€šéç¯©é¸")
    print(f"ğŸ“Š ç¬¬äºŒéšæ®µçµæœ: {len(strategy.filter_results)} å¼µåœ–ç‰‡é€šéåŒ¹é…åº¦æª¢æŸ¥")
    
    return strategy


def example_text2image2image_custom_params():
    """ç¯„ä¾‹ 2: è‡ªå®šç¾©åƒæ•¸çš„ Text2Image2Image"""
    print("\n" + "="*60)
    print("ç¯„ä¾‹ 2: è‡ªå®šç¾©åƒæ•¸çš„ Text2Image2Image")
    print("="*60)
    
    vision_manager = VisionManagerBuilder() \
        .with_vision_model('openrouter') \
        .with_text_model('openrouter') \
        .with_random_models(True) \
        .build()
    
    config = GenerationConfig(
        generation_type='text2image2image',
        character='kirby',
        prompt='Kirby floating in space with stars',
        workflow_path='configs/workflow/nova-anime-xl.json',
        output_dir='output_media/t2i2i_custom',
        image_system_prompt='stable_diffusion_prompt',
        similarity_threshold=0.85,  # è¼ƒä½çš„é–¾å€¼ï¼Œä¿ç•™æ›´å¤šåœ–ç‰‡
        additional_params={
            'strategies': {
                'text2image2image': {
                    'first_stage': {
                        'images_per_description': 6,  # ç¬¬ä¸€éšæ®µç”Ÿæˆæ›´å¤šåœ–ç‰‡
                    },
                    'second_stage': {
                        'images_per_input': 2,  # ç¬¬äºŒéšæ®µæ¯å€‹è¼¸å…¥ç”Ÿæˆ 2 å¼µ
                        'denoise': 0.55,  # è¼ƒä½çš„ denoiseï¼Œæ›´æ¥è¿‘åŸåœ–
                        'i2i_workflow_path': 'configs/workflow/example/image_to_image.json'
                    }
                }
            }
        }
    )
    
    strategy = StrategyFactory.get_strategy(
        'text2image2image',
        vision_manager=vision_manager
    )
    strategy.load_config(config)
    
    print(f"\nğŸ“ è‡ªå®šç¾©åƒæ•¸:")
    print(f"   - ç¬¬ä¸€éšæ®µç”Ÿæˆ: {config.additional_params['strategies']['text2image2image']['first_stage']['images_per_description']} å¼µ")
    print(f"   - ç›¸ä¼¼åº¦é–¾å€¼: {config.similarity_threshold}")
    print(f"   - ç¬¬äºŒéšæ®µæ¯å€‹è¼¸å…¥: {config.additional_params['strategies']['text2image2image']['second_stage']['images_per_input']} å¼µ")
    print(f"   - Denoise: {config.additional_params['strategies']['text2image2image']['second_stage']['denoise']}")
    
    strategy.generate_description()
    strategy.generate_media()
    strategy.analyze_media_text_match(similarity_threshold=0.8)
    
    print(f"\nâœ… ç”Ÿæˆå®Œæˆï¼")
    print(f"ğŸ“Š ç¬¬ä¸€éšæ®µé€šéç¯©é¸: {len(strategy.first_stage_images)} å¼µ")
    print(f"ğŸ“Š ç¬¬äºŒéšæ®µé€šéæª¢æŸ¥: {len(strategy.filter_results)} å¼µ")
    
    return strategy


def example_text2image2image_two_character():
    """ç¯„ä¾‹ 3: é›™è§’è‰²äº’å‹•çš„ Text2Image2Image"""
    print("\n" + "="*60)
    print("ç¯„ä¾‹ 3: é›™è§’è‰²äº’å‹•çš„ Text2Image2Image")
    print("="*60)
    
    vision_manager = VisionManagerBuilder() \
        .with_vision_model('openrouter') \
        .with_text_model('openrouter') \
        .with_random_models(True) \
        .build()
    
    config = GenerationConfig(
        generation_type='text2image2image',
        character='kirby',
        secondary_character='waddle dee',  # æ¬¡è¦è§’è‰²
        prompt='friendship and adventure',
        workflow_path='configs/workflow/nova-anime-xl.json',
        output_dir='output_media/t2i2i_two_char',
        image_system_prompt='two_character_interaction_generate_system_prompt',  # ä½¿ç”¨é›™è§’è‰²æç¤ºè©
        similarity_threshold=0.9,
        additional_params={
            'strategies': {
                'text2image2image': {
                    'first_stage': {
                        'images_per_description': 4
                    },
                    'second_stage': {
                        'images_per_input': 1,
                        'denoise': 0.6,
                        'i2i_workflow_path': 'configs/workflow/example/image_to_image.json'
                    }
                }
            }
        }
    )
    
    strategy = StrategyFactory.get_strategy(
        'text2image2image',
        vision_manager=vision_manager
    )
    strategy.load_config(config)
    
    print(f"\nğŸ“ ä¸»è§’è‰²: {config.character}")
    print(f"ğŸ“ æ¬¡è¦è§’è‰²: {config.secondary_character}")
    print(f"ğŸ“ æç¤ºè©: {config.prompt}")
    
    strategy.generate_description()
    print(f"ğŸ“ ç”Ÿæˆçš„æè¿°: {strategy.descriptions[0] if strategy.descriptions else 'N/A'}")
    
    strategy.generate_media()
    strategy.analyze_media_text_match(similarity_threshold=0.8)
    
    print(f"\nâœ… ç”Ÿæˆå®Œæˆï¼")
    print(f"ğŸ“Š ç¬¬ä¸€éšæ®µé€šéç¯©é¸: {len(strategy.first_stage_images)} å¼µ")
    print(f"ğŸ“Š ç¬¬äºŒéšæ®µé€šéæª¢æŸ¥: {len(strategy.filter_results)} å¼µ")
    
    return strategy


def main():
    """ä¸»å‡½æ•¸"""
    print("\n" + "="*60)
    print("Text2Image2Image ä½¿ç”¨ç¯„ä¾‹")
    print("å…©éšæ®µç”Ÿæˆï¼šText2Image -> ç¯©é¸ -> Image2Image")
    print("="*60)
    
    examples = {
        '1': ('åŸºæœ¬çš„ Text2Image2Image ç”Ÿæˆ', example_text2image2image_basic),
        '2': ('è‡ªå®šç¾©åƒæ•¸', example_text2image2image_custom_params),
        '3': ('é›™è§’è‰²äº’å‹•', example_text2image2image_two_character),
    }
    
    print("\nè«‹é¸æ“‡è¦é‹è¡Œçš„ç¯„ä¾‹:")
    for key, (name, _) in examples.items():
        print(f"  {key}. {name}")
    print("  q. é€€å‡º")
    
    choice = input("\nè«‹è¼¸å…¥é¸é … (1-3/q): ").strip().lower()
    
    if choice == 'q':
        print("\nğŸ‘‹ å†è¦‹ï¼")
        return
    
    try:
        if choice in examples:
            name, func = examples[choice]
            func()
        else:
            print("\nâŒ ç„¡æ•ˆçš„é¸é …")
            return
        
        print("\n" + "="*60)
        print("âœ… ç¯„ä¾‹åŸ·è¡Œå®Œæˆï¼")
        print("="*60)
        print("\nğŸ’¡ æç¤ºï¼š")
        print("   - ç¬¬ä¸€éšæ®µåœ–ç‰‡ä¿å­˜åœ¨: output_dir/first_stage/")
        print("   - ç¬¬äºŒéšæ®µåœ–ç‰‡ä¿å­˜åœ¨: output_dir/second_stage/")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ¶ä¸­æ–·åŸ·è¡Œ")
    except Exception as e:
        print(f"\nâŒ åŸ·è¡Œå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()

