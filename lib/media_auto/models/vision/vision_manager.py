from typing import List, Optional, Dict, Any
import re
import os
import time
from lib.media_auto.models.interfaces.ai_model import AIModelInterface, ModelConfig
from lib.media_auto.models.vision.model_registry import ModelRegistry
from configs.prompt.image_system_guide import *
from configs.prompt.video_system_guide import *
from utils.retry_decorator import vision_api_retry
from utils.logger import setup_logger

class VisionContentManager:
    """è™•ç†åœ–ç‰‡å…§å®¹åˆ†æèˆ‡ç”Ÿæˆçš„é¡åˆ¥"""
    def __init__(self, 
                 vision_model: AIModelInterface,
                 text_model: AIModelInterface,
                 prompts_config: dict):
        self.vision_model = vision_model
        self.text_model = text_model
        self.prompts = prompts_config
    
    @vision_api_retry(max_attempts=5)
    def extract_image_content(self, image_path: str, **kwargs) -> str:
        """åˆ†æå·²æœ‰åœ–ç‰‡ä¸¦æå–å…§å®¹æè¿°"""
        print(f"æå–åœ–ç‰‡å…§å®¹ {image_path}...")
        messages = [{
            'role': 'user',
            'content': self.prompts['describe_image_prompt']
        }]
        result = self.vision_model.chat_completion(
            messages=messages,
            images=[image_path],
            **kwargs
        )
        print(f"åœ–ç‰‡ {image_path} å…§å®¹æå–æˆåŠŸ")
        return result
    
    @vision_api_retry(max_attempts=3)
    def analyze_image_text_similarity(self, 
                                    text: str, 
                                    image_path: str, 
                                    main_character: str = '',
                                    **kwargs) -> str:
        """åˆ†æåœ–ç‰‡èˆ‡æ–‡æœ¬æè¿°çš„ç›¸ä¼¼åº¦
        
        è¿”å› LLM çš„åŸå§‹éŸ¿æ‡‰å­—ç¬¦ä¸²ï¼Œéœ€è¦å¾ŒçºŒè§£æç‚ºæ•¸å€¼ã€‚
        éŸ¿æ‡‰æ ¼å¼å¯èƒ½å¤šæ¨£ï¼Œä¾‹å¦‚ï¼š"0.85", "ç›¸ä¼¼åº¦: 0.85", "0.85/1.0", "85%" ç­‰ã€‚
        """
        print(f"åˆ†æåœ–ç‰‡ {image_path}...")
        messages = [
            {
                'role': 'system',
                'content': self.prompts['text_image_similarity_prompt']
            },
            {
                'role': 'user',
                'content': f'main_character: {main_character} and image description: {text}'
            }
        ]
        
        result = self.vision_model.chat_completion(
            messages=messages,
            images=[image_path],
            **kwargs
        )
        print(f"åœ–ç‰‡ {image_path} åˆ†ææˆåŠŸ")
        return result
    
    @vision_api_retry(max_attempts=5)
    def generate_image_prompts(self, user_input: str, system_prompt_key: str = 'stable_diffusion_prompt', **kwargs) -> str:
        """æ ¹æ“šç”¨æˆ¶è¼¸å…¥ç”Ÿæˆåœ–ç‰‡æè¿°æç¤ºè©"""
        
        # é©—è­‰ user_input ä¸ç‚ºç©º
        if not user_input or not str(user_input).strip():
            raise ValueError(f"user_input (é—œéµè©) ä¸èƒ½ç‚ºç©ºï¼ç•¶å‰å€¼: {repr(user_input)}")
        
        user_input = str(user_input).strip()
        
        actual_key_to_use = system_prompt_key
        if system_prompt_key not in self.prompts:
            print(f"Warning: Prompt key '{system_prompt_key}' not found in prompts configuration. Falling back to default 'stable_diffusion_prompt'.")
            actual_key_to_use = 'stable_diffusion_prompt'

        print(f"Using image system prompt key: {actual_key_to_use}")
        print(f"ğŸ“ å‚³éçµ¦ LLM çš„ user_input (é—œéµè©): {user_input}")
        
        messages = [
            {'role': 'system', 'content': self.prompts[actual_key_to_use]},
            {'role': 'user', 'content': user_input}
        ]
        result = self.text_model.chat_completion(messages=messages, **kwargs)
        if not result or not result.strip():
            raise ValueError("API è¿”å›ç©ºçµæœ")
        if '</think>' in result:  # deepseek r1 will have <think>...</think> format
            result = result.split('</think>')[-1].strip()
        return result

    def generate_video_prompts(self, user_input: str, system_prompt_key: str = 'video_description_system_prompt', **kwargs) -> str:
        """æ ¹æ“šç”¨æˆ¶è¼¸å…¥ç”Ÿæˆè¦–é »æè¿°æç¤ºè©"""
        
        actual_key_to_use = system_prompt_key
        if system_prompt_key not in self.prompts:
            print(f"Warning: Prompt key '{system_prompt_key}' not found in prompts configuration. Falling back to default 'video_description_system_prompt'.")
            actual_key_to_use = 'video_description_system_prompt'

        print(f"Using video system prompt key: {actual_key_to_use}")
        messages = [
            {'role': 'system', 'content': self.prompts[actual_key_to_use]},
            {'role': 'user', 'content': user_input}
        ]
        result = self.text_model.chat_completion(messages=messages, **kwargs)
        if '</think>' in result:  # deepseek r1 will have <think>...</think> format
            result = result.split('</think>')[-1].strip()
        return result
    
    @vision_api_retry(max_attempts=3)
    def generate_audio_description(self, image_path: str, video_description: str = '', **kwargs) -> str:
        """æ ¹æ“šåœ–ç‰‡å’Œå½±ç‰‡æè¿°ç”ŸæˆéŸ³é »æè¿°
        
        Args:
            image_path: åœ–ç‰‡è·¯å¾‘
            video_description: å½±ç‰‡æè¿°ï¼ˆå¯é¸ï¼‰
            **kwargs: å…¶ä»–åƒæ•¸
            
        Returns:
            éŸ³é »æè¿°ï¼ˆ1-3å€‹é—œéµå­—ï¼Œç”¨é€—è™Ÿåˆ†éš”ï¼‰
        """
        print(f"ç”ŸæˆéŸ³é »æè¿°ï¼Œåœ–ç‰‡: {image_path}, å½±ç‰‡æè¿°: {video_description}")
        
        # æ§‹å»ºè¼¸å…¥å…§å®¹
        user_content = ""
        if video_description:
            user_content = f"Video description: {video_description}\n\nAnalyze the image and generate audio keywords."
        else:
            user_content = "Analyze the image and generate audio keywords."
        
        messages = [
            {'role': 'system', 'content': self.prompts.get('audio_description_prompt', 'Generate 1-3 English sound keywords based on the image.')},
            {'role': 'user', 'content': user_content}
        ]
        
        result = self.vision_model.chat_completion(
            messages=messages,
            images=[image_path],
            **kwargs
        )
        
        # æ¸…ç†çµæœï¼Œåªä¿ç•™é—œéµå­—
        result = result.strip()
        # ç§»é™¤å¯èƒ½çš„ "Sound:" ç­‰å‰ç¶´
        if ':' in result:
            result = result.split(':', 1)[-1].strip()
        
        print(f"éŸ³é »æè¿°ç”ŸæˆæˆåŠŸ: {result}")
        return result
    
    def generate_seo_hashtags(self, description: str, **kwargs) -> str:
        """ç”Ÿæˆ SEO å„ªåŒ–çš„ hashtags"""
        messages = [
            {'role': 'system', 'content': self.prompts['seo_hashtag_prompt']},
            {'role': 'user', 'content': description}
        ]
        return self.text_model.chat_completion(messages=messages, **kwargs)

    def generate_input_prompt(self, character, extra='', prompt_type='arbitrary_input_system_prompt') -> str:
        """ç”Ÿæˆä»»æ„è¼¸å…¥çš„è½‰æ›çµæœ"""
        messages = [
            {'role': 'system', 'content': self.prompts[prompt_type]},
            {'role': 'user', 'content': f"""Central Figure: {character}, central figure's name must be in the final response! {extra}"""}
        ]
        result = self.text_model.chat_completion(messages=messages)    
        if '</think>' in result:  # deepseek r1 will have <think>...</think> format
            result = result.split('</think>')[-1].strip()
        
        messages = [
            {'role': 'system', 'content': f"As an expert editor, distill the text's essence. You must preserve the principal character's name, along with the original style and emotion. Keep the output under 30 words."},
            {'role': 'user', 'content': f"""Central Figure: {character}, central figure's name must be in the final response! {result}"""}
        ]
        result = self.text_model.chat_completion(messages=messages)   

        if '</think>' in result:  # deepseek r1 will have <think>...</think> format
            result = result.split('</think>')[-1].strip()         
        
        return result

    def generate_two_character_interaction_prompt(self, main_character, secondary_character, prompt='', style='', **kwargs) -> str:
        """ç”Ÿæˆé›™è§’è‰²äº’å‹•çš„æç¤ºè©"""
        # æ§‹å»ºè¼¸å…¥æ ¼å¼ï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦å­—æ®µ
        user_input = f"""
        Main Role: {main_character}
        Secondary Role: {secondary_character}
        """

        # åªæœ‰ç•¶ style ä¸ç‚ºç©ºæ™‚æ‰åŠ ä¸Š Style æ¬„ä½
        if style and style.strip():
            user_input += f"""
        Style: {style}
        """
        
        # å¦‚æœæœ‰åŸå§‹promptï¼Œå°‡å…¶ç´å…¥è¼¸å…¥
        if prompt and prompt.strip():
            user_input += f"""
            Original Context: {prompt.strip()}
            """
                    
        messages = [
            {'role': 'system', 'content': self.prompts['two_character_interaction_generate_system_prompt']},
            {'role': 'user', 'content': user_input}
        ]
        
        result = self.text_model.chat_completion(messages=messages, **kwargs)
        if '</think>' in result:  # deepseek r1 will have <think>...</think> format
            result = result.split('</think>')[-1].strip()
        
        return result

    def analyze_media_text_match(self, 
                               media_paths: List[str],
                               descriptions: List[str],
                               main_character: str,
                               similarity_threshold: float = 0.9,
                               **kwargs) -> List[Dict[str, Any]]:
        """åˆ†æåœ–æ–‡åŒ¹é…åº¦ä¸¦éæ¿¾çµæœ
        
        Args:
            media_paths: åœ–ç‰‡è·¯å¾‘åˆ—è¡¨
            descriptions: æè¿°æ–‡å­—åˆ—è¡¨
            main_character: ä¸»è¦è§’è‰²åç¨±
            similarity_threshold: ç›¸ä¼¼åº¦é–¾å€¼
            **kwargs: å…¶ä»–åƒæ•¸
            
        Returns:
            éæ¿¾å¾Œçš„çµæœåˆ—è¡¨ï¼Œæ¯å€‹çµæœåŒ…å«ï¼š
            - image_path: åœ–ç‰‡è·¯å¾‘
            - description: å°æ‡‰çš„æè¿°
            - similarity: ç›¸ä¼¼åº¦åˆ†æ•¸
        """
        start_time = time.time()
        total_results = []
        
        logger = setup_logger('mediaoverload')
        
        for media_path in media_paths:
            print(f'é€²è¡Œæ–‡åœ–åŒ¹é…ç¨‹åº¦åˆ¤æ–·ä¸­ : {media_path}\n')
            logger.debug(f'åˆ†ææ–‡ä»¶: {media_path}')

            # å˜—è©¦åŒ¹é…ç¬¬ä¸€éšæ®µçš„æ–‡ä»¶åæ ¼å¼: {anything}_d{idx}_{i}
            # ä½¿ç”¨æ›´éˆæ´»çš„æ¨¡å¼ï¼Œä¸ä¾è³´è§’è‰²åç¨±çš„ç²¾ç¢ºåŒ¹é…
            match = re.search(r'_d(\d+)_\d+\.', media_path, re.IGNORECASE)
            
            # å¦‚æœç¬¬ä¸€éšæ®µåŒ¹é…å¤±æ•—ï¼Œå˜—è©¦åŒ¹é…ç¬¬äºŒéšæ®µçš„æ–‡ä»¶åæ ¼å¼: {anything}_i2i_{idx}_{i}
            if not match:
                match = re.search(r'_i2i_(\d+)_\d+\.', media_path, re.IGNORECASE)
            
            # å¦‚æœéƒ½åŒ¹é…å¤±æ•—ï¼Œå˜—è©¦åŒ¹é…å½±ç‰‡æ ¼å¼: {anything}_i2v_{idx}_{i}
            if not match:
                match = re.search(r'_i2v_(\d+)_\d+\.', media_path, re.IGNORECASE)
            
            # å¦‚æœéƒ½åŒ¹é…å¤±æ•—ï¼Œå˜—è©¦åŒ¹é…å½±ç‰‡æ ¼å¼: {anything}_video_d{idx}_{i}
            if not match:
                match = re.search(r'_video_d(\d+)_\d+\.', media_path, re.IGNORECASE)
            
            # å¦‚æœéƒ½åŒ¹é…å¤±æ•—ï¼Œå˜—è©¦åŒ¹é… sticker æ ¼å¼: {anything}_sticker_{idx}_{i}
            if not match:
                match = re.search(r'_sticker_(\d+)_\d+\.', media_path, re.IGNORECASE)
            
            # å¦‚æœéƒ½åŒ¹é…å¤±æ•—ï¼Œè·³éé€™å€‹æ–‡ä»¶
            if not match:
                logger.warning(f'âš ï¸  è­¦å‘Šï¼šç„¡æ³•å¾æ–‡ä»¶åè§£ææè¿°ç´¢å¼•: {media_path}')
                print(f'âš ï¸  è­¦å‘Šï¼šç„¡æ³•å¾æ–‡ä»¶åè§£ææè¿°ç´¢å¼•: {media_path}')
                continue

            desc_index = int(match.group(1))

            # ç¢ºä¿ç´¢å¼•åœ¨æœ‰æ•ˆç¯„åœå…§
            # å¦‚æœç´¢å¼•è¶…å‡ºç¯„åœï¼Œä½¿ç”¨ç¬¬ä¸€å€‹æè¿°ï¼ˆé©ç”¨æ–¼å–®ä¸€æè¿°å°æ‡‰å¤šå¼µåœ–ç‰‡çš„æƒ…æ³ï¼‰
            if desc_index >= len(descriptions):
                logger.debug(f'æè¿°ç´¢å¼• {desc_index} è¶…å‡ºç¯„åœï¼ˆå…±æœ‰ {len(descriptions)} å€‹æè¿°ï¼‰ï¼Œä½¿ç”¨ç¬¬ä¸€å€‹æè¿°')
                desc_index = 0

            similarity_raw = self.analyze_image_text_similarity(
                text=descriptions[desc_index],
                image_path=media_path,
                main_character=main_character,
                **kwargs
            )
            
            total_results.append({
                'media_path': media_path,
                'description': descriptions[desc_index],
                'similarity': similarity_raw  # åŸå§‹å­—ç¬¦ä¸²éŸ¿æ‡‰
            })
            time.sleep(3)  # google free tier rate limit
        
        logger = setup_logger('mediaoverload')
        logger.info(f'é–‹å§‹è§£æ {len(total_results)} å€‹ç›¸ä¼¼åº¦åˆ†æçµæœ')
        
        # éæ¿¾çµæœ
        filter_results = []
        for row in total_results:
            try:
                similarity_str = str(row['similarity']).strip()
                logger.debug(f'åŸå§‹ç›¸ä¼¼åº¦éŸ¿æ‡‰: {similarity_str[:100]}')
                
                # å¾å­—ç¬¦ä¸²ä¸­æå–æ•¸å­—ï¼ˆè™•ç† LLM å¯èƒ½è¿”å›çš„å„ç¨®æ ¼å¼ï¼‰
                # ä¾‹å¦‚ï¼š"0.85", "ç›¸ä¼¼åº¦: 0.85", "0.85åˆ†", "0.85/1.0", "0.85/1", "85%" ç­‰
                # å„ªå…ˆå˜—è©¦æå– 0-1 ä¹‹é–“çš„å°æ•¸
                similarity_value = None
                
                # ç­–ç•¥1: ç›´æ¥åŒ¹é… 0-1 ä¹‹é–“çš„å°æ•¸ï¼ˆåŒ…æ‹¬ 0.0, 1.0, 0, 1ï¼‰
                match = re.search(r'\b(0(?:\.\d+)?|1(?:\.0+)?|0\.\d+|1\.0)\b', similarity_str)
                if match:
                    similarity_value = float(match.group())
                else:
                    # ç­–ç•¥2: åŒ¹é…ç™¾åˆ†æ¯”æ ¼å¼ï¼ˆå¦‚ "85%" -> 0.85ï¼‰
                    percent_match = re.search(r'(\d+(?:\.\d+)?)\s*%', similarity_str, re.IGNORECASE)
                    if percent_match:
                        similarity_value = float(percent_match.group(1)) / 100.0
                    else:
                        # ç­–ç•¥3: åŒ¹é…åˆ†æ•¸æ ¼å¼ï¼ˆå¦‚ "0.85/1.0" æˆ– "85/100"ï¼‰
                        fraction_match = re.search(r'(\d+(?:\.\d+)?)\s*/\s*(\d+(?:\.\d+)?)', similarity_str)
                        if fraction_match:
                            numerator = float(fraction_match.group(1))
                            denominator = float(fraction_match.group(2))
                            if denominator > 0:
                                similarity_value = numerator / denominator
                        else:
                            # ç­–ç•¥4: æå–ä»»ä½•æ•¸å­—ä¸¦åˆ¤æ–·æ˜¯å¦åœ¨åˆç†ç¯„åœå…§
                            number_match = re.search(r'(\d+(?:\.\d+)?)', similarity_str)
                            if number_match:
                                num = float(number_match.group(1))
                                # å¦‚æœæ•¸å­—åœ¨ 0-100 ç¯„åœå…§ï¼Œå¯èƒ½æ˜¯ç™¾åˆ†æ¯”
                                if 0 <= num <= 100:
                                    similarity_value = num / 100.0
                                # å¦‚æœæ•¸å­—åœ¨ 0-1 ç¯„åœå…§ï¼Œç›´æ¥ä½¿ç”¨
                                elif 0 <= num <= 1:
                                    similarity_value = num
                
                if similarity_value is not None:
                    # ç¢ºä¿åˆ†æ•¸åœ¨ 0-1 ç¯„åœå…§
                    similarity_value = max(0.0, min(1.0, similarity_value))
                    
                    # æ›´æ–° row ä¸­çš„ similarity ç‚ºæ•¸å­—
                    row['similarity'] = similarity_value
                    
                    logger.info(f'åœ–ç‰‡ {os.path.basename(row["media_path"])} ç›¸ä¼¼åº¦: {similarity_value:.3f} (é–¾å€¼: {similarity_threshold:.3f})')
                    
                    if similarity_value >= similarity_threshold:
                        filter_results.append(row)
                        logger.info(f'  âœ… é€šéç¯©é¸')
                    else:
                        logger.info(f'  âŒ æœªé€šéç¯©é¸ï¼ˆä½æ–¼é–¾å€¼ {similarity_threshold:.3f}ï¼‰')
                else:
                    logger.warning(f'âš ï¸  ç„¡æ³•å¾éŸ¿æ‡‰ä¸­æå–ç›¸ä¼¼åº¦åˆ†æ•¸: {similarity_str[:100]}...')
                    # å¦‚æœç„¡æ³•è§£æï¼Œè¨˜éŒ„åŸå§‹éŸ¿æ‡‰ä»¥ä¾¿èª¿è©¦
                    row['similarity_raw'] = similarity_str
                    row['similarity'] = None
                    continue
            except Exception as e:
                logger.error(f'âš ï¸  è§£æç›¸ä¼¼åº¦åˆ†æ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}, éŸ¿æ‡‰: {str(row.get("similarity", ""))[:100]}...')
                import traceback
                logger.error(traceback.format_exc())
                continue
                
        logger.info(f'åˆ†æåœ–æ–‡åŒ¹é…ç¨‹åº¦å®Œæˆï¼Œå…±åˆ†æ {len(total_results)} å¼µåœ–ç‰‡ï¼Œç¯©é¸å‡º {len(filter_results)} å¼µï¼ˆé–¾å€¼: {similarity_threshold:.3f}ï¼‰')
        logger.info(f'åˆ†æåœ–æ–‡åŒ¹é…ç¨‹åº¦ èŠ±è²» : {time.time() - start_time:.2f} ç§’')
        
        # å¦‚æœæ²’æœ‰é€šéç¯©é¸çš„çµæœï¼Œè¨˜éŒ„æ‰€æœ‰ç›¸ä¼¼åº¦åˆ†æ•¸ä»¥ä¾¿èª¿è©¦
        if len(filter_results) == 0 and len(total_results) > 0:
            logger.warning('âš ï¸  æ²’æœ‰ä»»ä½•åœ–ç‰‡é€šéç›¸ä¼¼åº¦ç¯©é¸ï¼Œä»¥ä¸‹æ˜¯æ‰€æœ‰ç›¸ä¼¼åº¦åˆ†æ•¸ï¼š')
            for row in total_results:
                similarity_val = row.get('similarity')
                if isinstance(similarity_val, (int, float)):
                    logger.warning(f'  {os.path.basename(row["media_path"])}: {similarity_val:.3f}')
                else:
                    logger.warning(f'  {os.path.basename(row["media_path"])}: ç„¡æ³•è§£æ ({str(similarity_val)[:50]})')
        
        return filter_results

class VisionManagerBuilder:
    """Vision Manager å»ºæ§‹å™¨"""
    def __init__(self):
        self.vision_model_type = 'ollama'
        self.text_model_type = 'ollama'
        self.vision_config = {'model_name': 'llava:13b', 'temperature': 0.3}
        self.text_config = {'model_name': 'llama3.2', 'temperature': 0.3}
        self.use_random_models = False  # æ–°å¢ï¼šæ˜¯å¦ä½¿ç”¨éš¨æ©Ÿæ¨¡å‹é¸æ“‡
        self.prompts_config = {
            'seo_hashtag_prompt': seo_hashtag_prompt,
            'stable_diffusion_prompt': stable_diffusion_prompt,
            'describe_image_prompt': describe_image_prompt,
            'text_image_similarity_prompt': text_image_similarity_prompt,
            'arbitrary_input_system_prompt': arbitrary_input_system_prompt,
            'guide_seo_article_system_prompt': guide_seo_article_system_prompt,
            'unbelievable_world_system_prompt': unbelievable_world_system_prompt,
            'buddhist_combined_image_system_prompt': buddhist_combined_image_system_prompt,
            'fill_missing_details_system_prompt': fill_missing_details_system_prompt,
            'two_character_interaction_generate_system_prompt': two_character_interaction_generate_system_prompt,
            'black_humor_system_prompt': black_humor_system_prompt,
            'video_description_system_prompt': video_description_system_prompt,
            'sticker_prompt_system_prompt': sticker_prompt_system_prompt,
            'warm_scene_description_system_prompt': warm_scene_description_system_prompt,
            'cinematic_stable_diffusion_prompt': cinematic_stable_diffusion_prompt,
            'conceptual_logo_design_prompt': conceptual_logo_design_prompt,
            'audio_description_prompt': audio_description_prompt,
            'sticker_motion_system_prompt': sticker_motion_system_prompt

        }
    
    def with_vision_model(self, model_type: str, **config):
        """è¨­ç½®è¦–è¦ºæ¨¡å‹"""
        self.vision_model_type = model_type
        # å¦‚æœåˆ‡æ›äº†æ¨¡å‹é¡å‹ï¼Œé‡ç½®é…ç½®ç‚ºè©²é¡å‹çš„é è¨­å€¼
        if model_type == 'gemini':
            self.vision_config = {'model_name': 'gemini-flash-lite-latest', 'temperature': 0.3}
        elif model_type == 'ollama':
            self.vision_config = {'model_name': 'llava:13b', 'temperature': 0.3}
        elif model_type == 'openrouter':
            self.vision_config = {'temperature': 0.3}  # model_name å°‡ç”±éš¨æ©Ÿé¸æ“‡æˆ–æ˜ç¢ºæŒ‡å®š
        else:
            # æœªçŸ¥é¡å‹ï¼Œé‡ç½®ç‚ºåŸºæœ¬é…ç½®
            self.vision_config = {'temperature': 0.3}
        
        # æ›´æ–°æä¾›çš„é…ç½®
        if config:
            self.vision_config.update(config)
        return self
    
    def with_text_model(self, model_type: str, **config):
        """è¨­ç½®æ–‡æœ¬æ¨¡å‹"""
        self.text_model_type = model_type
        # å¦‚æœåˆ‡æ›äº†æ¨¡å‹é¡å‹ï¼Œé‡ç½®é…ç½®ç‚ºè©²é¡å‹çš„é è¨­å€¼
        if model_type == 'gemini':
            self.text_config = {'model_name': 'gemini-flash-lite-latest', 'temperature': 0.3}
        elif model_type == 'ollama':
            self.text_config = {'model_name': 'llama3.2:latest', 'temperature': 0.3}
        elif model_type == 'openrouter':
            self.text_config = {'temperature': 0.3}  # model_name å°‡ç”±éš¨æ©Ÿé¸æ“‡æˆ–æ˜ç¢ºæŒ‡å®š
        else:
            # æœªçŸ¥é¡å‹ï¼Œé‡ç½®ç‚ºåŸºæœ¬é…ç½®
            self.text_config = {'temperature': 0.3}
        
        # æ›´æ–°æä¾›çš„é…ç½®
        if config:
            self.text_config.update(config)
        return self
    
    def with_random_models(self, enabled: bool = True):
        """å•Ÿç”¨éš¨æ©Ÿæ¨¡å‹é¸æ“‡ (åƒ…é©ç”¨æ–¼ OpenRouter)"""
        self.use_random_models = enabled
        return self
    
    def build(self) -> 'VisionContentManager':
        """å»ºæ§‹ VisionContentManager å¯¦ä¾‹"""
        vision_model_class = ModelRegistry.get_model(self.vision_model_type)
        text_model_class = ModelRegistry.get_model(self.text_model_type)
        
        # å¦‚æœå•Ÿç”¨éš¨æ©Ÿæ¨¡å‹é¸æ“‡ä¸”ä½¿ç”¨ OpenRouterï¼Œå‰‡éš¨æ©Ÿé¸æ“‡æ¨¡å‹
        vision_config = self.vision_config.copy()
        text_config = self.text_config.copy()
        
        logger = setup_logger('mediaoverload')
        
        if self.use_random_models and self.vision_model_type == 'openrouter':
            from lib.media_auto.models.vision.model_registry import OpenRouterModel
            vision_config['model_name'] = OpenRouterModel.get_random_free_vision_model()
            logger.info(f"éš¨æ©Ÿé¸æ“‡çš„ Vision æ¨¡å‹: {vision_config['model_name']}")
            
        if self.use_random_models and self.text_model_type == 'openrouter':
            from lib.media_auto.models.vision.model_registry import OpenRouterModel
            text_config['model_name'] = OpenRouterModel.get_random_free_text_model()
            logger.info(f"éš¨æ©Ÿé¸æ“‡çš„ Text æ¨¡å‹: {text_config['model_name']}")
        
        vision_model = vision_model_class(ModelConfig(**vision_config))
        text_model = text_model_class(ModelConfig(**text_config))
        
        return VisionContentManager(
            vision_model=vision_model,
            text_model=text_model,
            prompts_config=self.prompts_config
        ) 